library(tidyr)
library(stringr)
library(dplyr)
library(mice)
library(corrplot)
library(VIM)

Data = read.csv("C:\\Users\\rafae\\Documents\\AulasS1\\Reconhecimento de padrões\\trabalho rp\\CSVPadroesv2.csv", header = TRUE)

Data <- head(Data, -5)

#Coloca a DB com dados por cada país
Data <- Data %>%
  select(-Series.Code) %>%
  spread(key = Series.Name, value = X2015..YR2015.) %>%
  mutate_all(~na_if(.,".."))

names(Data) <- gsub(" ", ".", names(Data))
names(Data) <- gsub(",", "", names(Data))
names(Data) <- gsub("\\(", "", names(Data))
names(Data) <- gsub("\\$", "D", names(Data))
names(Data) <- gsub("\\)", "", names(Data))
names(Data) <- gsub("\\%", "", names(Data))

#Verifica os indices que têm mais de 20% de Nulos
prop_na <- colMeans(is.na(Data))
print(prop_na)
colunas_manter <- names(prop_na[prop_na <= 0.2])
colunas_manter

#Retira os indices com mais de 20% de nulos
Data <- Data[colunas_manter]

#Verifica os paises que têm mais de 20% de Nulos
prop_na_lines <- rowMeans(is.na(Data))
print(prop_na_lines)
prop_na_lines_df = data.frame(Pais = Data$Country.Name , Percentagem = prop_na_lines)
paises_manter <- prop_na_lines_df %>%
  filter(Percentagem < 0.2) %>%
  pull(Pais)

#Retira os paises com mais de 20% de nulos
Data <- Data %>%
  filter(Country.Name %in% paises_manter)

#Ajustar colunas para numeric 
{
  Data$Adjusted.net.national.income.per.capita.current.USD <- as.numeric(Data$Adjusted.net.national.income.per.capita.current.USD)
  Data$Birth.rate.crude.per.1000.people <- as.numeric(Data$Birth.rate.crude.per.1000.people)
  Data$Current.health.expenditure..of.GDP <- as.numeric(Data$Current.health.expenditure..of.GDP)
  Data$Foreign.direct.investment.net.BoP.current.USD <- as.numeric(Data$Foreign.direct.investment.net.BoP.current.USD)
  Data$GDP.current.USD <- as.numeric(Data$GDP.current.USD)
  Data$GDP.per.capita.current.USD <- as.numeric(Data$GDP.per.capita.current.USD)
  Data$Individuals.using.the.Internet..of.population <- as.numeric(Data$Individuals.using.the.Internet..of.population)
  Data$Inflation.GDP.deflator.annual. <- as.numeric(Data$Inflation.GDP.deflator.annual.)
  Data$Labor.force.total <- as.numeric(Data$Labor.force.total)
  Data$Life.expectancy.at.birth.total.years <- as.numeric(Data$Life.expectancy.at.birth.total.years)
  Data$Mortality.rate.infant.per.1000.live.births <- as.numeric(Data$Mortality.rate.infant.per.1000.live.births)
  Data$People.using.at.least.basic.drinking.water.services..of.population <- as.numeric(Data$People.using.at.least.basic.drinking.water.services..of.population)
  Data$Population.total <- as.numeric(Data$Population.total)
  Data$School.enrollment.primary..gross <- as.numeric(Data$School.enrollment.primary..gross)
  Data$Suicide.mortality.rate.per.100000.population <- as.numeric(Data$Suicide.mortality.rate.per.100000.population)
  }
# Conversão colunas de percentagem para decimais
Data$Current.health.expenditure..of.GDP <- Data$Current.health.expenditure..of.GDP / 100
Data$Individuals.using.the.Internet..of.population <- Data$Individuals.using.the.Internet..of.population / 100
Data$People.using.at.least.basic.drinking.water.services..of.population <- Data$People.using.at.least.basic.drinking.water.services..of.population / 100


# Encontra os Outliers e substitui por NA
for (col in names(Data)) {
  if (is.numeric(Data[[col]])) {
    quartiles <- quantile(Data[[col]], probs=c(.25, .75), na.rm = TRUE)
    
    iQRange <- IQR(Data[[col]], na.rm = TRUE)
    lowerLimit <- quartiles[1] - 1.5 * iQRange
    upperLimit <- quartiles[2] + 1.5 * iQRange
    
    # Substituir outliers por NA diretamente na coluna existente
    Data[[col]][Data[[col]] < lowerLimit | Data[[col]] > upperLimit] <- NA
  }
}

str(Data)

#Realizar a imputação KNN 
Data_kNN <- kNN(Data, k = 5, imp_var = FALSE)

###Normalizar###
# Identificar as colunas numéricas
colunas_numericas <- sapply(Data_kNN, is.numeric)

# Normalizar manualmente todas as colunas numéricas para o intervalo [0, 1] (método Min-Max)
normalize_minmax <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

# Aplicar a função de normalização a todas as colunas numéricas
Data_kNN[, colunas_numericas] <- lapply(Data_kNN[, colunas_numericas], normalize_minmax)





####ACP####
#Summary and covariance matrix
AAA <- Data_kNN[,3:17]
summary(AAA)
round(var(AAA),2)

#scatterplot
pairs(AAA, pch = 19, lower.panel = NULL)

#correlation matrix
correlation <- cor(AAA)
round(correlation,3)

#corrplot
par(oma = c(2, 2, 2, 2)) # space around for text
corrplot.mixed(correlation, 
               order = "hclust", #order of variables
               tl.pos = "lt", #text left + top
               upper = "ellipse",
               tl.cex = 0.5)

#Bartlett test - valor p baixo -> rejeita-se H0 -> há diferenças entre a matriz de correlação observada e a matriz de identidade 
cortest.bartlett(correlation)

#KMO - Overall e individual MSA com valores relativamente altos
KMO(correlation)



# PCA´s
pc15 <- principal(AAA, nfactors=15, rotate="none", scores=TRUE) 

#Eigenvalues - Variances of the principal components 
round(pc15$values,3)
#CRITÉRIO DE KAISER - reter os quatro primeiros componentes principais, já que são os únicos com valores maiores que 1

#Screeplot - Find the elbow
plot(pc15$values, type = "b", main = "Scree plot dos Dados", xlab = "Number of PC", ylab = "Eigenvalue")
#De acordo com este gráfico, o "cotovelo" está no 3, por isso reter as 3 primeiras componentes principais

#Olhar para a cumulative Var
pc15$loadings

#Com base nas Cumulative Var e no critério de Keiser, escolher PC4

#Let's extract a 4 component solution
pc4 <- principal(AAA, nfactors=4, rotate="none")
pc4
#Let's rotate the 4 components using varimax
pc4r <- principal(AAA, nfactors=4, rotate="varimax")
pc4r$loadings

#Communalities
round(pc4r$communality,4)



#Escolher nomes para cada PCA



#Compute the scores
pc4sc <- principal(AAA, nfactors=4, rotate="none", scores=TRUE) 
round(pc4sc$scores,4)

#Add scores to the data set as new variables
Data_kNN$pc1 <- pc4sc$scores[,1]
Data_kNN$pc2 <- pc4sc$scores[,2]
Data_kNN$pc3 <- pc4sc$scores[,3]
Data_kNN$pc4 <- pc4sc$scores[,4]
#Save the new data set in excel format
setwd("C:\\2\\")
write.xlsx(Data_kNN, file = "NewDecathlon.xlsx", 
           sheetName = "PCAscores", col.names = TRUE, 
           row.names = TRUE, append = FALSE)


#Depict the scatterplot of PC1 vs PC2
plot(Data_kNN$pc1, Data_kNN$pc2, pch = 19,xlim = c(-2,3),
     ylim = c(-3,2), xlab="PC1", ylab="PC2", main = "Scores: PC1 vs Pc2")
text(Data_kNN$pc1, Data_kNN$pc2-0.1, Data_kNN[,2]) #(x,y,labels)

#Exemplo de correlação entre PC1 e uma variável qualquer
#Compute correlation: Points vs PC1 
#cor(Data_kNN$Points,Data_kNN$pc1)
####DESENVOLVIMENTO TIPOLOGIA####

summary(Data)
str(Data)
